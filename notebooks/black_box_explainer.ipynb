{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ml_editor.data_processing import (\n",
    "    format_raw_df,\n",
    "    get_split_by_author,\n",
    "    add_text_features_to_df,\n",
    "    get_vectorized_series,\n",
    "    get_feature_vector_and_label\n",
    ")\n",
    "\n",
    "from ml_editor.model_v1 import get_model_probabilities_for_input_texts\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "random.seed(42)\n",
    "\n",
    "data_path=Path(\"../data/writers.csv\")\n",
    "df=pd.read_csv(data_path)\n",
    "df=format_raw_df(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=add_text_features_to_df(df.loc[df[\"is_question\"]].copy())\n",
    "train_df, test_df=get_split_by_author(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=Path(\"../models/model_1.pkl\")\n",
    "clf=joblib.load(model_path)\n",
    "vectorizer_path=Path(\"../models/vectorizer_1.pkl\")\n",
    "vectorizer=joblib.load(vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"vectors\"]=get_vectorized_series(train_df[\"full_text\"].copy(), vectorizer)\n",
    "test_df[\"vectors\"]=get_vectorized_series(test_df[\"full_text\"].copy(), vectorizer)\n",
    "\n",
    "features=[\n",
    "    \"action_verb_full\",\n",
    "    \"question_mark_full\",\n",
    "    \"text_len\",\n",
    "    \"language_question\"\n",
    "]\n",
    "\n",
    "X_train, y_train=get_feature_vector_and_label(train_df, features)\n",
    "X_test, y_test=get_feature_vector_and_label(test_df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_one_instance(instance, class_names):\n",
    "    explainer=LimeTextExplainer(class_names=class_names)\n",
    "    exp=explainer.explain_instance(instance, get_model_probabilities_for_input_texts, num_features=6)\n",
    "    return exp\n",
    "\n",
    "\n",
    "def visualize_one_exp(features, labels, index, class_names=[\"Low score\", \"High Score\"]):\n",
    "    exp=explain_one_instance(features[index], class_names=class_names)\n",
    "    print(f\"Index : {index}\")\n",
    "    print(f\"True class : {class_names[labels[index]]}\")\n",
    "    exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvisualize_one_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m, in \u001b[0;36mvisualize_one_exp\u001b[1;34m(features, labels, index, class_names)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_one_exp\u001b[39m(features, labels, index, class_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh Score\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m----> 8\u001b[0m     exp\u001b[38;5;241m=\u001b[39m\u001b[43mexplain_one_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue class : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[labels[index]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mexplain_one_instance\u001b[1;34m(instance, class_names)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain_one_instance\u001b[39m(instance, class_names):\n\u001b[0;32m      2\u001b[0m     explainer\u001b[38;5;241m=\u001b[39mLimeTextExplainer(class_names\u001b[38;5;241m=\u001b[39mclass_names)\n\u001b[1;32m----> 3\u001b[0m     exp\u001b[38;5;241m=\u001b[39m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_model_probabilities_for_input_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exp\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\gans\\lib\\site-packages\\lime\\lime_text.py:413\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    406\u001b[0m indexed_string \u001b[38;5;241m=\u001b[39m (IndexedCharacters(\n\u001b[0;32m    407\u001b[0m     text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow, mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string)\n\u001b[0;32m    408\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_level \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m    409\u001b[0m                   IndexedString(text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow,\n\u001b[0;32m    410\u001b[0m                                 split_expression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_expression,\n\u001b[0;32m    411\u001b[0m                                 mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string))\n\u001b[0;32m    412\u001b[0m domain_mapper \u001b[38;5;241m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[1;32m--> 413\u001b[0m data, yss, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data_labels_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexed_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(yss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\gans\\lib\\site-packages\\lime\\lime_text.py:482\u001b[0m, in \u001b[0;36mLimeTextExplainer.__data_labels_distances\u001b[1;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[0;32m    480\u001b[0m     data[i, inactive] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    481\u001b[0m     inverse_data\u001b[38;5;241m.\u001b[39mappend(indexed_string\u001b[38;5;241m.\u001b[39minverse_removing(inactive))\n\u001b[1;32m--> 482\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m distances \u001b[38;5;241m=\u001b[39m distance_fn(sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix(data))\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, labels, distances\n",
      "File \u001b[1;32md:\\Project 1\\notebooks\\..\\ml_editor\\model_v1.py:39\u001b[0m, in \u001b[0;36mget_model_probabilities_for_input_texts\u001b[1;34m(text_array)\u001b[0m\n\u001b[0;32m     37\u001b[0m text_ser\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(text_array, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     38\u001b[0m text_ser\u001b[38;5;241m=\u001b[39madd_v1_features(text_ser)\n\u001b[1;32m---> 39\u001b[0m vec_features\u001b[38;5;241m=\u001b[39m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m num_features\u001b[38;5;241m=\u001b[39mtext_ser[FEATURE_ARR]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     41\u001b[0m features\u001b[38;5;241m=\u001b[39mhstack([vec_features, num_features])\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\gans\\lib\\site-packages\\scipy\\sparse\\_construct.py:781\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks], \u001b[38;5;28mformat\u001b[39m, dtype)\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks], \u001b[38;5;28mformat\u001b[39m, dtype, return_spmatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "visualize_one_exp(list(test_df[\"full_text\"]), list(y_test), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_one_exp(list(test_df[\"full_text\"]), list(y_test), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 44\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sorted_contributions\n\u001b[0;32m     40\u001b[0m label_to_text \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow score\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh score\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     43\u001b[0m }\n\u001b[1;32m---> 44\u001b[0m sorted_contributions \u001b[38;5;241m=\u001b[39m \u001b[43mget_statistical_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_model_probabilities_for_input_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_to_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m, in \u001b[0;36mget_statistical_explanation\u001b[1;34m(test_set, sample_size, model_pipeline, label_dict)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# First find contributing words to each class\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sample_sentences:\n\u001b[1;32m---> 11\u001b[0m     probabilities\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     curr_label\u001b[38;5;241m=\u001b[39mprobabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margmax()\n\u001b[0;32m     13\u001b[0m     labels_to_sentences[curr_label]\u001b[38;5;241m.\u001b[39mappend(sentence)\n",
      "File \u001b[1;32md:\\Project 1\\notebooks\\..\\ml_editor\\model_v1.py:39\u001b[0m, in \u001b[0;36mget_model_probabilities_for_input_texts\u001b[1;34m(text_array)\u001b[0m\n\u001b[0;32m     37\u001b[0m text_ser\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(text_array, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     38\u001b[0m text_ser\u001b[38;5;241m=\u001b[39madd_v1_features(text_ser)\n\u001b[1;32m---> 39\u001b[0m vec_features\u001b[38;5;241m=\u001b[39m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m num_features\u001b[38;5;241m=\u001b[39mtext_ser[FEATURE_ARR]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     41\u001b[0m features\u001b[38;5;241m=\u001b[39mhstack([vec_features, num_features])\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\gans\\lib\\site-packages\\scipy\\sparse\\_construct.py:781\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks], \u001b[38;5;28mformat\u001b[39m, dtype)\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks], \u001b[38;5;28mformat\u001b[39m, dtype, return_spmatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "def get_statistical_explanation(test_set, sample_size, model_pipeline, label_dict):\n",
    "    sample_sentences=random.sample(test_set, sample_size)\n",
    "    explainer=LimeTextExplainer()\n",
    "\n",
    "    labels_to_sentences=defaultdict(list)\n",
    "    contributors=defaultdict(dict)\n",
    "\n",
    "\n",
    "    # First find contributing words to each class\n",
    "    for sentence in sample_sentences:\n",
    "        probabilities=model_pipeline([sentence])\n",
    "        curr_label=probabilities[0].argmax()\n",
    "        labels_to_sentences[curr_label].append(sentence)\n",
    "        exp=explainer.explain_instance(sentence, model_pipeline, num_features=6, labels=[curr_label])\n",
    "        listed_explaination=exp.as_list(label=curr_label)\n",
    "\n",
    "        for word, contributing_weight in listed_explaination:\n",
    "            if word in contributors[curr_label]:\n",
    "                contributors[curr_label][word].append(contributing_weight)\n",
    "            else:\n",
    "                contributors[curr_label][word]=contributing_weight\n",
    "    \n",
    "    # Average each word contribution to a class, and sort them by impact\n",
    "    average_contributions = {}\n",
    "    sorted_contributions = {}\n",
    "    for label,lexica in contributors.items():\n",
    "        curr_label = label\n",
    "        curr_lexica = lexica\n",
    "        average_contributions[curr_label] = pd.Series(index=curr_lexica.keys())\n",
    "        for word,scores in curr_lexica.items():\n",
    "            average_contributions[curr_label].loc[word] = np.sum(np.array(scores))/sample_size\n",
    "        detractors = average_contributions[curr_label].sort_values()\n",
    "        supporters = average_contributions[curr_label].sort_values(ascending=False)\n",
    "        sorted_contributions[label_dict[curr_label]] = {\n",
    "            'detractors':detractors,\n",
    "             'supporters': supporters\n",
    "        }\n",
    "    return sorted_contributions\n",
    "\n",
    "label_to_text = {\n",
    "    0: 'Low score',\n",
    "    1: 'High score',\n",
    "}\n",
    "sorted_contributions = get_statistical_explanation(list(test_df[\"full_text\"]), 500, get_model_probabilities_for_input_texts, label_to_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_words(top_scores, top_words, botton_scores, bottom_words, name):\n",
    "    y_pos=np.arange(len(top_words))\n",
    "    top_pairs=[(a, b) for a, b in zip(top_words, top_scores)]\n",
    "    top_pairs=sorted(top_pairs, key=lambda x: x[1])\n",
    "\n",
    "    bottom_pairs=[(a, b) for a, b in zip(bottom_words, botton_scores)]\n",
    "    bottom_pairs=sorted(bottom_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_words=[a[0] for a in top_pairs]\n",
    "    top_scores=[a[1] for a in top_pairs]\n",
    "\n",
    "    bottom_words=[a[0] for a in bottom_pairs]\n",
    "    bottom_scores=[a[1] for a in bottom_pairs]\n",
    "\n",
    "    fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.barh(y_pos, bottom_scores, align='center', alpha=0.5)\n",
    "    plt.title('Low score', fontsize=20)\n",
    "    plt.yticks(y_pos, bottom_words, fontsize=14)\n",
    "    plt.suptitle('Key words', fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=20)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.barh(y_pos, top_scores, align='center', alpha=0.5)\n",
    "    plt.title('High Score', fontsize=20)\n",
    "    plt.yticks(y_pos, top_words, fontsize=14)\n",
    "    plt.suptitle(name, fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=20)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words=sorted_contributions[\"High score\"]['supporters'][:10].index.tolist()\n",
    "top_scores=sorted_contributions[\"High score\"]['supporters'][:10].tolist()\n",
    "bottom_words=sorted_contributions[\"High score\"]['detractors'][:10].index.tolist()\n",
    "bottom_scores=sorted_contributions[\"High score\"]['detractors'][:10].tolist()\n",
    "\n",
    "\n",
    "plot_important_words(top_scores, top_words, bottom_scores, bottom_words, \"Most important words for relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
